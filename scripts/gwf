#!/Users/mailund/anaconda/bin/python

import os
import os.path
import sys
import argparse
import pkg_resources
import gwf_workflow
import subprocess
from gwf_workflow.backends import AVAILABLE_BACKENDS
from gwf_workflow.configurations import read_configurations
from gwf_workflow.colours import *
from gwf_workflow.performance import *

# This gets the installed version of gwf that is actually being used by the script.
package_version = pkg_resources.require("gwf")[0].version
config = read_configurations()

parser = argparse.ArgumentParser(
    version=package_version,
    description="""
    Grid WorkFlow (v{version}) -- Keeps track of the status of jobs in a workflow and submits jobs that needs to be run.
    """.format(version=package_version),
    epilog="""
    For questions, comments or bug-reports contact <mailund@birc.au.dk> or go to https://github.com/mailund/gwf/issues/
    """)

parser.add_argument('-f', '--file', 
                    default='workflow.py', dest='workflow_file',
                    help='Workflow file if not the default (workflow.py).')
parser.add_argument('-d', '--dry-run', default=False, action='store_true',
                    help='The submit script will be printed but not executed.')
parser.add_argument('-s', '--status', default=False, action='store_true',
                    help='Print status of targets.')
parser.add_argument('--printspec', default=False, action='store_true',
                    help='Print shell commands for targets.')
parser.add_argument('-k', '--cancel', default=False, action='store_true',
                    help='Cancel queued jobs for targets')
parser.add_argument('-c', '--clean', default=False, action='store_true',
                    help='Delete output files generated by a target.')
parser.add_argument('--verbose', default=False, action='store_true', help='Verbose output.')
parser.add_argument('-p', '--performance', default=False, action='store_true',
                    help='Display performance of completed jobs.')


default_backend = config.get('gwf', 'backend')
parser.add_argument('--backend', default=default_backend,
                    choices=AVAILABLE_BACKENDS.keys(),
                    help='''Grid backend to use. If not specified the default ({default}) will be used.
                    '''.format(default=default_backend))


parser.add_argument('targets', nargs='*',
                    help='The targets to process. The default is all targets that are not completed or already running')

args = parser.parse_args()
if not os.path.exists(args.workflow_file):
    parser.error("The specified workflow file '{}' does not exist.\n".format(args.workflow_file))


# Set the backend based on defaults or arguments...
gwf_workflow.BACKEND = AVAILABLE_BACKENDS[args.backend]()

cancel_command = gwf_workflow.BACKEND.build_cancel_command

if args.performance:

    if os.path.isfile('.jobs.ids'):

        with open('.jobs.ids', 'r') as job_file:
            
            finished_jobs = []
            unfinished_jobs = []

            for line in job_file:
                
                job_id, job_name = line.split()
                
                # Get job info provided by SLURM.
                job_info    = subprocess.check_output('jobinfo {job_id}'.format(job_id=job_id), shell=True)
                state       = re.search(r'^State *: (.*)', job_info, re.MULTILINE).group(1).strip()
                
                if state == 'COMPLETED':

                    # Grab various information from SLURM job status.
                    cores           = re.search(r'^Cores *: (.*)', job_info, re.MULTILINE).group(1).strip()
                    node_list       = re.search(r'^Nodes *: (.*)', job_info, re.MULTILINE).group(1).strip()
                    used_walltime   = re.search(r'^Used walltime *: (.*)', job_info, re.MULTILINE).group(1).strip()
                    used_cpu_time   = re.search(r'^Used CPU time *: (.*)', job_info, re.MULTILINE).group(1).strip()
                    max_memory_used = re.search(r'^Max Mem used *: (.*) .*', job_info, re.MULTILINE).group(1).strip()
                    memory_reserved = re.search(r'^Mem reserved *: ([^/]+)/.*', job_info, re.MULTILINE).group(1).strip()

                    # Expand the compact node list format to comma-separated list of nodes.
                    node_list = subprocess.check_output('scontrol show hostname {node_list} | paste -d, -s'.format(node_list=node_list), shell=True)
                    nodes = len(node_list.split(','))

                    # Store all information needed to calculate performance.
                    finished_jobs.append({
                        'id' : job_id,
                        'name' : job_name,
                        'cores' : cores,
                        'nodes' : nodes,
                        'used_walltime' : used_walltime,
                        'used_cpu_time' : used_cpu_time,
                        'max_memory_used' : max_memory_used,
                        'memory_reserved' : memory_reserved })

                else:

                    unfinished_jobs.append((job_id, state, job_name))
        
        if len(finished_jobs) > 0:

            # Print header line.            
            print '{:>8} {:>6} {:>6} {:>14} {:>14} {:>16} {:>16} {:>16} {:>19}  {}'.format(
                  'job_id', 'nodes', 'cores', 'used_walltime', 'used_cpu_time','max_memory_used',
                  'memory_reserved', 'cpu_performance', 'memory_performance', 'name')

            for job in finished_jobs:
                
                print '{job_id:>8} {nodes:>6} {cores:>6} {used_walltime:>14} {used_cpu_time:>14} {max_memory_used:>16} {memory_reserved:>16} {cpu_performance:>16} {memory_performance:>19}  {job_name}'.format(
                
                    # Print information from SLURM job info.
                    job_id          = job['id'],
                    nodes           = job['nodes'],
                    cores           = job['cores'],
                    used_walltime   = job['used_walltime'],
                    used_cpu_time   = job['used_cpu_time'],
                    max_memory_used = job['max_memory_used'],
                    memory_reserved = job['memory_reserved'],
                    job_name        = job['name'],

                    # Calculate performace based on values above.
                    cpu_performance     = job_cpu_performance(job),
                    memory_performance  = job_memory_performace(job)
                
                )

        # Print list of jobs not completed (for whatever reason).
        if len(unfinished_jobs) > 0:
            
            print

            max_state_length = 0
            for _, state, _ in unfinished_jobs:
                max_state_length = max(max_state_length, len(state))

            for job_id, state, job_name in unfinished_jobs:
                format_string = '{job_id:>8}  {state:<%d}  {job_name}' % max_state_length
                print format_string.format(job_id=job_id, state=state, job_name=job_name)

    sys.exit(0)

execfile(args.workflow_file)
from gwf_workflow.workflow import build_workflow, schedule, dependencies
workflow = build_workflow()

if args.clean:
    if len(args.targets) == 0:
        parser.error("No targets specified to clean.\nThis is never a good idea and gwf refuses to clean default targets.\n")

    if args.dry_run:
        for target in args.targets:
            print 'Cleaning', target, 'will delete the following files:'
            print workflow.targets[target].get_existing_outfiles()
            print
    else:
        for target in args.targets:
            workflow.targets[target].clean_target()
        
    sys.exit(0)

if len(args.targets) > 0:
    all_targets = args.targets
else:
    # take all terminal nodes as default targets
    all_targets = [n.target.name for n in workflow.targets.values() if len(n.dependents) == 0]


def split_tasks(tasks):
    up_to_date, in_queue, to_schedule = [], [], []
    for task in tasks:
        if task.job_in_queue:
            in_queue.append(task)
        elif task.should_run:
            to_schedule.append(task)
        else:
            up_to_date.append(task)
    return up_to_date, in_queue, to_schedule


if args.status:
    all_scheduled = set()
    for target in all_targets:

        tasks = dependencies(workflow.targets, target)
        up_to_date, in_queue, to_schedule = split_tasks(tasks)

        n_up_to_date, n_in_queue, n_to_schedule = len(up_to_date), len(in_queue), len(to_schedule)
        n_total = n_up_to_date + n_in_queue + n_to_schedule
        progress_width = 30
        in_queue_bars = int(float(n_in_queue * progress_width) / n_total)
        to_schedule_bars = int(float(n_to_schedule * progress_width) / n_total)
        up_to_date_bars = progress_width - in_queue_bars - to_schedule_bars

        progress_bar = "{}{}{}".format(COLORS['green']+'#'*up_to_date_bars,
                                       COLORS['yellow']+'#'*in_queue_bars,
                                       COLORS['red']+'#'*to_schedule_bars+CLEAR)
        print '{target} [{status}] ({count_done}/{count_queue}/{count_submit})'.format(
            target=(COLORS['bold']+target[:24]+CLEAR+'.'*35)[:35],
            status=progress_bar,
            count_done=COLORS['green']+'{}'.format(n_up_to_date).rjust(2)+CLEAR,
            count_queue=COLORS['yellow']+'{}'.format(n_in_queue).rjust(2)+CLEAR,
            count_submit=COLORS['red']+'{}'.format(n_to_schedule).rjust(2)+CLEAR)

        if args.verbose:
            for task in up_to_date:
                print COLORS['green'], task.target.name, CLEAR
            for task in in_queue:
                print COLORS['yellow'], task.target.name, CLEAR, '({}: {})'.format(task.job_id, task.job_queue_status)
            for task in to_schedule:
                print COLORS['red'], task.target.name, CLEAR
            print

elif args.cancel:
    for target_name in all_targets:

        job_ids = [task.job_id for task in dependencies(workflow.targets, target_name) if task.job_in_queue]
        if job_ids:
            print '{}Cancelling job computation of target'.format(COLORS['bold']), target_name, '{}'.format(CLEAR)
            command = cancel_command(job_ids)
            try:
                qsub = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
                qsub.stdout.read()
            except OSError, ex:
                print
                print COLORS['red'], COLORS['bold']
                print 'ERROR:', CLEAR,
                print "Couldn't execute the cancellation command {}'{}'{}.".format(COLORS['bold'], ' '.join(command), CLEAR)
                print ex
                print COLORS['red']
                print "Quiting cancellation", CLEAR
                print
                import sys ; sys.exit(2)

elif args.printspec:
    # for target_name, job in workflow.targets.items():
    for target_name in all_targets:
        job = workflow.targets[target_name]
        if job.job_in_queue:
            print "{}{}: {}{}".format(COLORS['yellow'], target_name, job.target.spec, CLEAR)
        elif job.should_run:
            print "{}{}: {}{}".format(COLORS['red'], target_name, job.target.spec, CLEAR)
        else:
            print "{}{}: {}{}".format(COLORS['green'], target_name, job.target.spec, CLEAR)

else:
    # Executing work flow!
    for target_name in all_targets:
        schedule, scheduled_jobs = workflow.get_execution_schedule(target_name)

        if len(schedule) == 0:
            continue

        print '{}Scheduling computation of target'.format(COLORS['bold']), target_name, '{}...'.format(CLEAR)
        for job in schedule:

            if job.job_id:
                print "Taget", job.target.name, "is already submitted ({})".format(job.job_id)
                continue

            dependents = [dependent for dependent in job.depends_on if dependent.target.name in scheduled_jobs]

            print "Submitting target", job.target.name,
            if len(dependents) > 0 and args.verbose:
                dependents_text = ["{}[{}]".format(dependent.target.name, dependent.job_id) for dependent in dependents]
                print "(depending on {})".format(', '.join(dependents_text)),
            print '...',

            if args.dry_run:
                # For a dry run we just finish here, but write the script so people can check it
                job.write_script()
                print
                continue

            job_id = job.submit(dependents)
            print job_id

            # Store job ids and job names. For use later if gwf is run with the --performace (-p) command line option.
            with open('.jobs.ids', 'a') as job_file:
                job_file.write('{job_id} {job_target_name}\n'.format(job_id=job_id, job_target_name=job.target.name))

        print
